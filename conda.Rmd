# `conda`
This is a compilation of a few terminal commands for managing different python environments using `conda`, with a brief introduction also pointing to the alternatives of `conda` environments. As a disclaimer I will use `conda` as a synonyme `anaconda`, the former is the abbreviated command you use inside your terminal.

## Introduction Code Reproducibility

Every code has a couple of dependencies that limit its reproducibility/portability

### Hard-coded dependencies
These are the obvious dependencies which are easily avoided by adhering to good coding practices.

- file paths
- random numbers or randomized code outcome

### Software dependencies
 Often your code will not run on another machine even if code and underlying data source have not been changed because of variations in the installation of the programming languages that you have been using. A typical data science project can depend on a number of installations on your machine. To name a few of them

- `R` *
- `R packages` *
- `python` *
- `python packages` *
- `pip`
- `git`
- `Java`
- `a C++ compiler`
- `pandoc`
- `latex`
- `phantom js`

The most important being `R` and `python` and the underlying packages which usually shoulder the workload of your code.

### System/Hardware dependencies
Then there is you machine in itself which has a specific get up:

- OS (32bit, 64bit)
- environment variable
- Hardware (number of cores, RAM, GPU)



### Programming language-based solutions
There are a number of strategies to reproducibly preserve either your `python` or your `R` environment. For R there is `packrat` and `checkpoint` and for `python` there is the `pip freeze` command, which preserves all packages and version in a `requirements.txt` file.

However these solutions are focused on snapshotting the programming language environment and do not consider any of the other tools and system configurations that might be necessary to run your code. 

### Environment-based solutions (`anaconda`)
`conda` environmnents use a bit of a more holistic approach, they too are focused on your programming language and the packages that are installed with it, but they provide a strategy for handling `R` and `python` simultaneously and they have a set of packages for which they offer their own support for. Meaning you can download the packages from a `conda` server and they are garanteed to be compatible with each other as long as they are being installed at the same time. However the `conda` environments are not garanteed to be platform independent. The list of supported packages depends on the OS. However anaconda will make an effort to replicate the environment as closely as possible. 

[list of all `python` packages managed by `anaconda`](https://docs.anaconda.com/anaconda/packages/pkg-docs)
[list of all `R` packages managed by `anaconda`](https://docs.anaconda.com/anaconda/packages/r-language-pkg-docs)


### Container-based solutions
The state of the art solution is a `docker` container, which containerizes everything (tools, drivers, environment variables, etc), this eases pushing code into procuction  as explained [here](https://www.dataquest.io/blog/docker-data-science/). There are even solutions for systems with specialized hardware configurations such as GPUs, as explained [here](https://indico.io/data-science-deployments-docker/)

# Managing `anaconda` environments

## `anaconda` navigator GUI

after installing the anaconda distribution you can run the navigator app, which allows you to create environments and manage
the installed packages. As always with these tools some commands will only work in the command line.

# Command Line 

condensated version of official [documentation](https://conda.io/docs/user-guide/tasks/manage-environments.html#removing-an-environment)

## Check installation
```
conda --version
```

## Create an environment
that contains `python` and `R`, we are specifiying r-base because conda will install the microsoft R distribution by default.
```
conda create --name myenv python=3.6 r-base=3.4.3
```


## Activate environment
will add your environment to your command line
```
conda activate myenv
```
## Deactivate environment
will remove your environment from your command line

```
conda deactivate
```
## Remove an environment
```
conda remove -name myenv --all
```

## Install packages and apps

### Channels
An important issue for `anaconda` are the channels where we can find tha packages that we want to install in our `anaconda` environments. Each environment contains a list of channels which will be searched from top to bottom for a package that we would like to install. `anaconda` will always prioritize the channel over the version number thus might not always install the latest versions. Each environment starts with the channel `defaults` which are the official channels

##### Add a channel to the bottom of the list
You want to make sure that the defaults channels rank high thus I recommend appending all new channels.
```
conda config --append channels conda-forge bioconductor
```

##### Add a channel to the top of the list
here you want to add your own channel containing your anaconda builds. 
```
conda config --prepend channels anaconda_username
```

### Install packages without build/compilation

*make sure the environment that you want to install to is active*

*we can install apps such as Rstudio, pip, etc (see anaconda launcher with the same synthax)*

* do not use `R; install.packages()`, packages installed that way cannot be tracked

##### from listed channel
```
conda install package_name
```

#### from pip
```
conda install pip
pip install package_name
pip install git+repos_url
```

### Install packages with build/compilation
This will be mostly required for `R` packages that cannot be found on `anaconda` ressources which unfortunately is true for most of the packages. Managing your `R` packages with `anaconda` takes a long time to set up if you already start with a large set of package requirements and can be efficient if you gradually build it up as you go. However you will not be cross platform compatible. You will have to more or less go through the same iterative steps on each platform you want to be compatible with. The reason is that `R` packages containing `C++` or `Fortran` code need different compilers depending on the operating system that you use. Some of these compilers are not referenced directly but they reference to another `R` package which is at the base of the dependency trail. There is the option of converting you package builds compiled on one platform to another which will work for the majority of the packages but not for all.

#### Workflow outline for creating an `R` environment

1. create an anaconda account where you will upload your packages to
2. enable automatic uploading after package building
3. create an environment inlcuding python, R, and r-essentials.
4. add personal R channel to the top of you channels list
5. add bioconductor and conda-forge to the end of your channels list
6. identify a package that you want to add to your environment which is not available from an anaconda source
7. download a skeleton from CRAN
8. build/compile the package
    - anaconda will create test environment in which the package will be built based on the requirements saved in the skeleton. For `R` packages it will only detect dependencies in the `DESCRIPTION` file.  
    - anaconda will look for the required packages in the channels and try to install whatever it finds. It will list all packages and sources it will install from. If it cannot find the necessary packages it will fail.  
9. Troubleshoot if compiling/building fails
    - Try to skim the error message for the incompatible package, however the error message is not always meaningful  
    - `R` Packages from conda-forge and bioconductor are likely to be outdated get them from CRAN as skeleton instead  
    - `R` packages have the `R` version that they were compiled for attached to the version number. Check if that matches the `r-base` version of your environment  
  - Packages that come from you own repository but have initially been built for another platform and contain `C++` or `Fortran` code must likely be rebuilt from skeleton for your present platform.
10. If building/compilation was successfull the package will be uploaded to our anaconda repository from where it can be installed
 
 #### List of R packages that contain `C++` or `fortran` and are not part of r-essentials
 - fastmatch
 - ff
 - ffbase
 - bit
 - spam
 - maps
 - dotcall64
 - fields
 - spam
 - mda
 - rlang (part of r-essentials but better to install the newest version)
 
 
#### Create an anaconda account and login, activate automated upload
create the account on [anaconda.org](https://anaconda.org)

```
anaconda anaconda login
conda config --set anaconda_upload yes
# anaconda logout
```

#### Create an anaconda account and login

### Install packages from external sources
This is where it gets complicated and where the situation is different for `R` and `python`. We could simply install packages from other sources (github, CRAN) manually in `R` (`install.packages()` or `devtools`) but `anaconda` will not track them and thus the environment will not be reproducible. 

**If available always use anaconda sources, however they are often outdated.**

We can easily find them by googeling the package name together with `anaconda`. **For python packages it is easier we can simply pip install them and the installation will be tracked given that the `anaconda` environment is activated.**

### Install packages that need to be built/compiled
This includes all packages from github/ CRAN/ self-developments. Some of them will nee

#### CRAN

this will download the repository to your current work directory
```
conda skeleton cran r-xgboost
```

```
conda skeleton cran r-xgboost
conda build r-xgboost
conda install --use-local r-xgboost
```

### Upload builds to `anaconda`
make sure to create an `anaconda` account first.

```
anaconda login
conda build r-xgboost
conda config --set anaconda_upload yes
anaconda logout

```

## None standard channels

conda config --append channels conda-forge
conda config --append channels bioconda

**If available always use anaconda sources**

## List packages

### environment activated
```
conda list
```

### environment not activated
```
conda list -name myenv
```

### is package installed in an environment
```
conda list -name myenv pandas
```
### exporting an environment to share
activate the environment that you want to export. It will save a `.yml` file into the current working directory
```
conda env export -f myenv.yml
```

### convert packages to other formats

```
for f in *.bz2; do conda convert -f --platform linux-64 -o ../linux-64 $f; done
```

